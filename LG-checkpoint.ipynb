{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6391891891891892\n",
      "{'C': 100, 'class_weight': None, 'max_iter': 100, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sys\n",
    "import xlwt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import time\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# 读取训练集数据\n",
    "training_dataset = pd.read_excel('training_dataset.xlsx')\n",
    "training_dataset.set_index([\"Unnamed: 0\"], inplace=True)\n",
    "training_dataset = training_dataset.T\n",
    "\n",
    "for i in training_dataset.columns:\n",
    "    if len(str(i)) == 1:\n",
    "        training_dataset.rename(columns={i:'00000'+str(i)}, inplace=True)\n",
    "    if len(str(i)) == 2:\n",
    "        training_dataset.rename(columns={i:'0000'+str(i)}, inplace=True)\n",
    "    if len(str(i)) == 3:\n",
    "        training_dataset.rename(columns={i:'000'+str(i)}, inplace=True)\n",
    "    if len(str(i)) == 4:\n",
    "        training_dataset.rename(columns={i:'00'+str(i)}, inplace=True)\n",
    "    if len(str(i)) == 5:\n",
    "        training_dataset.rename(columns={i:'0'+str(i)}, inplace=True)\n",
    "    if len(str(i)) == 6:\n",
    "        training_dataset.rename(columns={i:str(i)}, inplace=True)\n",
    "\n",
    "\n",
    "# GridSearchCV\n",
    "\n",
    "# split the data into independent 'X' and dependent 'Y' variables\n",
    "X = training_dataset.T.iloc[:, 1:106].values\n",
    "Y = training_dataset.T.iloc[:, 0].values\n",
    "\n",
    "# split the dataset into 80% training and 20% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "# scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "\n",
    "# fitting LG to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(Y_test,Y_pred)\n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "# 参数设置\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'C':[0.0001, 1, 100, 1000],\n",
    "          'max_iter':[1, 10, 100, 500],\n",
    "          'class_weight':['balanced', None],\n",
    "          'solver':['liblinear','sag','lbfgs','newton-cg']\n",
    "         }\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, param_grid=params, cv=10)\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
