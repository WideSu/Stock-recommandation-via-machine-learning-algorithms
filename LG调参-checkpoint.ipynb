{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sys\n",
    "import xlwt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import time\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练集数据\n",
    "training_dataset = pd.read_excel('training_dataset.xlsx')\n",
    "training_dataset.set_index([\"Unnamed: 0\"], inplace=True)\n",
    "training_dataset = training_dataset.T\n",
    "\n",
    "for i in training_dataset.columns:\n",
    "    if len(str(i)) == 1:\n",
    "        training_dataset.rename(columns={i:'00000'+str(i)}, inplace=True)\n",
    "    if len(str(i)) == 2:\n",
    "        training_dataset.rename(columns={i:'0000'+str(i)}, inplace=True)\n",
    "    if len(str(i)) == 3:\n",
    "        training_dataset.rename(columns={i:'000'+str(i)}, inplace=True)\n",
    "    if len(str(i)) == 4:\n",
    "        training_dataset.rename(columns={i:'00'+str(i)}, inplace=True)\n",
    "    if len(str(i)) == 5:\n",
    "        training_dataset.rename(columns={i:'0'+str(i)}, inplace=True)\n",
    "    if len(str(i)) == 6:\n",
    "        training_dataset.rename(columns={i:str(i)}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "\n",
    "# split the data into independent 'X' and dependent 'Y' variables\n",
    "X = training_dataset.T.iloc[:, 1:106].values\n",
    "Y = training_dataset.T.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into 80% training and 20% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Training Accuracy（Before）:  0.6658783783783784\n"
     ]
    }
   ],
   "source": [
    "# fitting LG to the Training set\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train, Y_train)\n",
    "print('LogisticRegression Training Accuracy（Before）: ', classifier.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting \n",
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Confusion Matrix (Before):  [[341  86]\n",
      " [185 128]]\n"
     ]
    }
   ],
   "source": [
    "# making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test,Y_pred)\n",
    "print('LogisticRegression Confusion Matrix (Before): ',cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Testing Accuracy (Before):  0.6337837837837837\n"
     ]
    }
   ],
   "source": [
    "print('LogisticRegression Testing Accuracy (Before): ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhaowen Yun\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n"
     ]
    }
   ],
   "source": [
    "C = [0.00000001, 0.000001, 0.0001, 0.01, 1, 10, 1000, 100000, 100000000, 100000000000000]\n",
    "# max_iter = [1, 10, 100, 500]\n",
    "# class_weight = ['balanced', None]\n",
    "# solver = ['liblinear','sag','lbfgs','newton-cg']\n",
    "\n",
    "parameters = {'C':C,\n",
    "#           'max_iter':max_iter,\n",
    "#           'class_weight':class_weight,\n",
    "#           'solver':solver\n",
    "             }\n",
    "\n",
    "grid_search = GridSearchCV(estimator=classifier,\n",
    "                          param_grid=parameters,\n",
    "                          scoring='accuracy',\n",
    "                          cv = 3,n_jobs = -1)\n",
    "\n",
    "grid_search = grid_search.fit(X_train,Y_train)\n",
    "accuracy_after = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Best Params:  {'C': 10}\n",
      "LogisticRegression Training Accuracy (After):  0.6432432432432432\n"
     ]
    }
   ],
   "source": [
    "print('LogisticRegression Best Params: ',grid_search.best_params_)\n",
    "print('LogisticRegression Training Accuracy (After): ',accuracy_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LG Confusion Matrix (After):  [[338  89]\n",
      " [190 123]]\n",
      "LG Testing Accuracy (After):  0.6229729729729729\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(\n",
    "#     class_weight=grid_search.best_params_['class_weight'], \n",
    "     C=grid_search.best_params_['C'],\n",
    "#     max_iter=grid_search.best_params_['max_iter'],\n",
    "#     solver=grid_search.best_params_['solver']\n",
    "                                )\n",
    "classifier.fit(X_train,Y_train)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "accuracy_after = accuracy_score(Y_test,Y_pred)\n",
    "cm_after = confusion_matrix(Y_test,Y_pred)\n",
    "print('LG Confusion Matrix (After): ',cm_after)\n",
    "print('LG Testing Accuracy (After): ',accuracy_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
